"""
le_eval.py - æœºæ¢°è‡‚æŠ•æ·ä»»åŠ¡è¯„ä¼°å’Œè®°å½•è„šæœ¬

ä¸»è¦åŠŸèƒ½:
1. è¯„ä¼°è®­ç»ƒå¥½çš„æŠ•æ·ç­–ç•¥
2. è®°å½•ç›®æ ‡å…³èŠ‚è§’åº¦åºåˆ—ç”¨äºçœŸå®æœºå™¨äººæ§åˆ¶
3. å¯è§†åŒ–æŠ•æ·ç»“æœ

ä½¿ç”¨ç¤ºä¾‹ï¼š
# åŸºæœ¬è¯„ä¼°ï¼ˆ10ä¸ªepisodesï¼‰
python le_eval.py -e so_arm_throwing --ckpt 700

# è®°å½•ç¬¬5ä¸ªepisodeçš„ç›®æ ‡å…³èŠ‚è§’åº¦åºåˆ—ï¼ˆNNè¾“å‡ºï¼Œç”¨äºæ§åˆ¶ï¼‰
python le_eval.py -e so_arm_throwing --ckpt 700 --record --record_type target --record_episode 5

# è®°å½•ç¬¬5ä¸ªepisodeçš„å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€åºåˆ—ï¼ˆæ‰§è¡ŒçŠ¶æ€ï¼Œç”¨äºåˆ†æï¼‰
python le_eval.py -e so_arm_throwing --ckpt 700 --record --record_type state --record_episode 5

# æŒ‡å®šå›ºå®šç›®æ ‡ä½ç½®å¹¶è®°å½•ç›®æ ‡è§’åº¦
python le_eval.py -e so_arm_throwing --ckpt 700 --target_x 1.0 --target_y 0.5 --record --record_type target --record_episode 0

è¾“å‡ºæ–‡ä»¶ï¼š
- robot_control_sequence_{type}_ep{N}.json: è¯¦ç»†çš„å…³èŠ‚è§’åº¦æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
- robot_control_script_{type}_ep{N}.py: å¯æ‰§è¡Œçš„æœºå™¨äººæ§åˆ¶/åˆ†æè„šæœ¬

è®°å½•ç±»å‹è¯´æ˜ï¼š
- target: è®°å½•NNè¾“å‡ºè®¡ç®—çš„ç›®æ ‡å…³èŠ‚è§’åº¦ï¼Œå¯ç›´æ¥ç”¨äºæœºå™¨äººæ§åˆ¶
- state: è®°å½•æœºå™¨äººæ‰§è¡Œåçš„å®é™…å…³èŠ‚ä½ç½®ï¼Œç”¨äºè½¨è¿¹åˆ†æå’Œæ€§èƒ½è¯„ä¼°

ç›®æ ‡å…³èŠ‚è§’åº¦æ ¼å¼ï¼š
{
    "shoulder_pan.pos": 0.0,      # å¯¹åº”ä»¿çœŸä¸­çš„Rotation_Rå…³èŠ‚
    "shoulder_lift.pos": -20.0,   # å¯¹åº”ä»¿çœŸä¸­çš„Pitch_Rå…³èŠ‚
    "elbow_flex.pos": 90.0,       # å¯¹åº”ä»¿çœŸä¸­çš„Elbow_Rå…³èŠ‚  
    "wrist_flex.pos": 0.0,        # å¯¹åº”ä»¿çœŸä¸­çš„Wrist_Pitch_Rå…³èŠ‚
    "wrist_roll.pos": 0.0,        # å¯¹åº”ä»¿çœŸä¸­çš„Wrist_Roll_Rå…³èŠ‚
    "gripper.pos": 0.0,           # é»˜è®¤gripperæ§åˆ¶ï¼ˆ0-100ï¼‰
}
"""
"""
le_eval.py - Robotic Arm Throwing Task Evaluation and Recording Script

Main Features:
1. Evaluate trained throwing strategies
2. Record target joint angle sequences for real robot control
3. Visualize throwing results

Usage Examples:
# Basic evaluation (10 episodes)
python le_eval.py -e so_arm_throwing --ckpt 700

# Record target joint angle sequence for episode 5 (NN output, for control)
python le_eval.py -e so_arm_throwing --ckpt 700 --record --record_type target --record_episode 5

# Record actual joint position state sequence for episode 5 (execution state, for analysis)
python le_eval.py -e so_arm_throwing --ckpt 700 --record --record_type state --record_episode 5

# Specify fixed target position and record target angles
python le_eval.py -e so_arm_throwing --ckpt 700 --target_x 1.0 --target_y 0.5 --record --record_type target --record_episode 0

Output Files:
- robot_control_sequence_{type}_ep{N}.json: Detailed joint angle data (JSON format)
- robot_control_script_{type}_ep{N}.py: Executable robot control/analysis script

Recording Type Description:
- target: Records NN output calculated target joint angles, can be directly used for robot control
- state: Records actual joint positions after robot execution, for trajectory analysis and performance evaluation

Target Joint Angle Format:
{
    "shoulder_pan.pos": 0.0,      # Corresponds to Rotation_R joint in simulation
    "shoulder_lift.pos": -20.0,   # Corresponds to Pitch_R joint in simulation
    "elbow_flex.pos": 90.0,       # Corresponds to Elbow_R joint in simulation
    "wrist_flex.pos": 0.0,        # Corresponds to Wrist_Pitch_R joint in simulation
    "wrist_roll.pos": 0.0,        # Corresponds to Wrist_Roll_R joint in simulation
    "gripper.pos": 0.0,           # Default gripper control (0-100)
}
"""

import argparse
import os
import pickle
import torch
import numpy as np
from importlib import metadata
import json
import time

# æ£€æŸ¥rsl_rlç‰ˆæœ¬
try:
    try:
        if metadata.version("rsl-rl"):
            raise ImportError
    except metadata.PackageNotFoundError:
        if metadata.version("rsl-rl-lib") != "2.2.4":
            raise ImportError
except (metadata.PackageNotFoundError, ImportError) as e:
    raise ImportError("è¯·å¸è½½ 'rsl_rl' å¹¶å®‰è£… 'rsl-rl-lib==2.2.4'.") from e

from rsl_rl.runners import OnPolicyRunner
import genesis as gs
from le_env import SoArmEnv

import matplotlib.pyplot as plt
from matplotlib.patches import Circle
import matplotlib.patches as mpatches

def convert_to_json_serializable(obj):
    """
    é€’å½’è½¬æ¢å¯¹è±¡ä¸­çš„numpyç±»å‹ä¸ºJSONå¯åºåˆ—åŒ–çš„PythonåŸç”Ÿç±»å‹
    """
    if isinstance(obj, dict):
        return {key: convert_to_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_json_serializable(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_to_json_serializable(item) for item in obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, (np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, torch.Tensor):
        return obj.cpu().numpy().tolist() if obj.numel() > 1 else obj.item()
    else:
        return obj

def map_joint_angles_to_robot(sim_angles):
    """
    å°†ä»¿çœŸå…³èŠ‚è§’åº¦æ˜ å°„åˆ°çœŸå®æœºå™¨äººå…³èŠ‚è§’åº¦
    
    ä»¿çœŸå…³èŠ‚é¡ºåº: ["Rotation_R", "Pitch_R", "Elbow_R", "Wrist_Pitch_R", "Wrist_Roll_R"]
    çœŸå®æœºå™¨äººå…³èŠ‚: shoulder_pan, shoulder_lift, elbow_flex, wrist_flex, wrist_roll
    """
    # å°†å¼§åº¦è½¬æ¢ä¸ºè§’åº¦
    sim_angles_deg = np.degrees(sim_angles)
    
    # æ˜ å°„å…³èŠ‚è§’åº¦ï¼ˆæ ¹æ®å®é™…æœºå™¨äººé…ç½®è°ƒæ•´ï¼‰
    robot_angles = {
        "shoulder_pan.pos": float(sim_angles_deg[0]),    # Rotation_R -> shoulder_pan
        "shoulder_lift.pos": float(sim_angles_deg[1]),   # Pitch_R -> shoulder_lift  
        "elbow_flex.pos": float(sim_angles_deg[2]),      # Elbow_R -> elbow_flex
        "wrist_flex.pos": float(sim_angles_deg[3]),      # Wrist_Pitch_R -> wrist_flex
        "wrist_roll.pos": float(sim_angles_deg[4]),      # Wrist_Roll_R -> wrist_roll
        "gripper.pos": 0.0,  # é»˜è®¤gripperä½ç½®
    }
    
    return robot_angles

def generate_robot_control_script(joint_sequence, output_path, episode_info, record_type):
    """
    ç”Ÿæˆå¯ä»¥ç›´æ¥æ§åˆ¶çœŸå®æœºå™¨äººçš„Pythonè„šæœ¬ - è§’åº¦æ–¹å‘è®­ç»ƒç‰ˆæœ¬
    """
    data_type_desc = {
        "target": "ç›®æ ‡å…³èŠ‚è§’åº¦åºåˆ— - ç¥ç»ç½‘ç»œè¾“å‡ºè®¡ç®—çš„æ§åˆ¶å‘½ä»¤",
        "state": "å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€åºåˆ— - æœºå™¨äººæ‰§è¡Œåçš„çœŸå®å…³èŠ‚ä½ç½®"
    }[record_type]
    
    usage_note = {
        "target": "æ³¨æ„: æ­¤æ•°æ®ä¸ºç›®æ ‡ä½ç½®å‘½ä»¤ï¼Œå¯ç›´æ¥ç”¨äºæœºå™¨äººæ§åˆ¶",
        "state": "æ³¨æ„: æ­¤æ•°æ®ä¸ºå®é™…æ‰§è¡ŒçŠ¶æ€ï¼Œç”¨äºè½¨è¿¹å¤ç°æ—¶éœ€è¦è½¬æ¢ä¸ºä½ç½®æ§åˆ¶å‘½ä»¤"
    }[record_type]
    
    script_content = '''#!/usr/bin/env python3
"""
è‡ªåŠ¨ç”Ÿæˆçš„æœºå™¨äººæ§åˆ¶è„šæœ¬ - è§’åº¦æ–¹å‘è®­ç»ƒ
åŸºäºä»¿çœŸepisodeçš„{}

Episodeä¿¡æ¯:
- ç›®æ ‡ä½ç½®: {}
- å‰å‘åå·®: {:.1f}Â°
- æŠ•æ·è·ç¦»: {:.3f}m
- Episodeå¥–åŠ±: {:.3f}
- æ€»æ­¥æ•°: {}
- æ§åˆ¶é¢‘ç‡: 50Hz (æ¯æ­¥0.02ç§’)
- æ•°æ®ç±»å‹: {}
- æ–¹å‘æˆåŠŸ: {}
- è·ç¦»æˆåŠŸ: {}
- ç»¼åˆæˆåŠŸ: {}

{}

å…³èŠ‚æ˜ å°„:
- shoulder_pan.pos:  ä»¿çœŸRotation_R -> æœºå™¨äººshoulder_pan
- shoulder_lift.pos: ä»¿çœŸPitch_R -> æœºå™¨äººshoulder_lift  
- elbow_flex.pos:    ä»¿çœŸElbow_R -> æœºå™¨äººelbow_flex
- wrist_flex.pos:    ä»¿çœŸWrist_Pitch_R -> æœºå™¨äººwrist_flex
- wrist_roll.pos:    ä»¿çœŸWrist_Roll_R -> æœºå™¨äººwrist_roll
"""

import time
from lerobot.common.robots import make_robot_from_config
from lerobot.common.robots.so101_follower.so101_follower import SO101FollowerConfig

# åˆ›å»ºé…ç½®
robot_cfg = SO101FollowerConfig(
    port="/dev/ttyACM0",         # ç«¯å£æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    id="follower_arm_1",
    use_degrees=True             # ä½¿ç”¨è§’åº¦æ§åˆ¶ï¼ˆæ¨èï¼‰
)

# ç›®æ ‡å…³èŠ‚è§’åº¦åºåˆ—ï¼ˆæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ—¶é—´æ­¥çš„ç›®æ ‡å…³èŠ‚è§’åº¦ï¼‰
joint_sequence = {}

def main():
    # åˆå§‹åŒ–å¹¶è¿æ¥
    robot = make_robot_from_config(robot_cfg)
    robot.connect()
    
    try:
        print("ğŸ¤– å¼€å§‹æ‰§è¡Œè§’åº¦æ–¹å‘è®­ç»ƒè®°å½•çš„å…³èŠ‚è§’åº¦åºåˆ—")
        print(f"æ€»æ­¥æ•°: {{len(joint_sequence)}}")
        print(f"é¢„è®¡æ‰§è¡Œæ—¶é—´: {{len(joint_sequence) * 0.02:.1f}}ç§’")
        print("\\nå…³èŠ‚è§’åº¦èŒƒå›´é¢„è§ˆ:")
        if len(joint_sequence) > 0:
            first_pos = joint_sequence[0]
            print(f"  shoulder_pan:  {{first_pos['shoulder_pan.pos']:.1f}}Â°")
            print(f"  shoulder_lift: {{first_pos['shoulder_lift.pos']:.1f}}Â°") 
            print(f"  elbow_flex:    {{first_pos['elbow_flex.pos']:.1f}}Â°")
            print(f"  wrist_flex:    {{first_pos['wrist_flex.pos']:.1f}}Â°")
            print(f"  wrist_roll:    {{first_pos['wrist_roll.pos']:.1f}}Â°")
            print(f"  gripper:       {{first_pos['gripper.pos']:.1f}}")
        
        print("\\næŒ‰Enterå¼€å§‹æ‰§è¡Œ...")
        input()
        
        for step, target_position in enumerate(joint_sequence):
            print(f"\\ræ­¥æ•°: {{step+1}}/{{len(joint_sequence)}}", end="", flush=True)
            
            # å‘é€ç›®æ ‡ä½ç½®
            robot.send_action(target_position)
            
            # ç­‰å¾…ä¸‹ä¸€æ­¥ï¼ˆä»¿çœŸé¢‘ç‡50Hz = 0.02ç§’ï¼‰
            time.sleep(0.02)
        
        print("\\nâœ… è§’åº¦æ–¹å‘åºåˆ—æ‰§è¡Œå®Œæˆï¼")
        print("ç­‰å¾…5ç§’è®©æœºå™¨äººç¨³å®š...")
        time.sleep(5.0)
        
    except KeyboardInterrupt:
        print("\\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\\nâŒ æ‰§è¡Œé”™è¯¯: {{e}}")
    finally:
        robot.disconnect()
        print("ğŸ”Œ æœºå™¨äººè¿æ¥å·²æ–­å¼€")

if __name__ == "__main__":
    main()
'''.format(
        data_type_desc,
        "å›ºå®šå‰å‘ç›®æ ‡", "[100, 0]",
        np.degrees(episode_info["direction_error"]),
        episode_info["throw_distance"],
        episode_info["episode_reward"],
        len(joint_sequence), record_type.upper(),
        'âœ…' if episode_info["direction_success"] else 'âŒ',
        'âœ…' if episode_info["distance_success"] else 'âŒ',
        'âœ…' if episode_info["overall_success"] else 'âŒ',
        usage_note, repr(joint_sequence)
    )
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    # ä½¿è„šæœ¬å¯æ‰§è¡Œ
    os.chmod(output_path, 0o755)

def visualize_throws(target_positions, landing_positions, circle_centers, target_radius, save_path):
    """å¯è§†åŒ–æŠ•æ·ç»“æœï¼Œæ”¯æŒåœ†å½¢ç›®æ ‡åŒºåŸŸ"""
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # ç»˜åˆ¶æœºæ¢°è‡‚åŸºåº§ä½ç½®
    base = Circle((0, 0), 0.1, color='black', label='æœºæ¢°è‡‚åŸºåº§')
    ax.add_patch(base)
    
    # ç»˜åˆ¶ç›®æ ‡åœ†å½¢åŒºåŸŸï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if circle_centers is not None and target_radius > 0:
        for i, center in enumerate(circle_centers):
            circle = Circle((center[0], center[1]), target_radius, 
                          fill=False, color='blue', linestyle='--', alpha=0.7)
            ax.add_patch(circle)
            # æ ‡è®°åœ†å¿ƒ
            ax.scatter(center[0], center[1], c='blue', marker='+', s=200, alpha=0.8)
    
    # ç»˜åˆ¶ç›®æ ‡ä½ç½®å’Œå®é™…è½ç‚¹
    for i, (target, landing) in enumerate(zip(target_positions, landing_positions)):
        # ç›®æ ‡ä½ç½®ï¼ˆç»¿è‰²ï¼‰
        ax.scatter(target[0], target[1], c='green', marker='x', s=100, alpha=0.8)
        # å®é™…è½ç‚¹ï¼ˆçº¢è‰²ï¼‰
        ax.scatter(landing[0], landing[1], c='red', marker='o', s=50, alpha=0.8)
        # è¿çº¿
        ax.plot([target[0], landing[0]], [target[1], landing[1]], 
                'gray', alpha=0.3, linewidth=1)
    
    # æ·»åŠ å›¾ä¾‹
    legend_handles = [
        mpatches.Patch(color='black', label='æœºæ¢°è‡‚åŸºåº§'),
        mpatches.Patch(color='green', label='ç›®æ ‡ä½ç½®'),
        mpatches.Patch(color='red', label='å®é™…è½ç‚¹')
    ]
    if circle_centers is not None and target_radius > 0:
        legend_handles.extend([
            mpatches.Patch(color='blue', label='ç›®æ ‡åœ†å¿ƒ'),
            mpatches.Patch(color='blue', label=f'ç›®æ ‡åŒºåŸŸ (åŠå¾„{target_radius:.1f}m)', fill=False)
        ])
    
    ax.legend(handles=legend_handles, loc='upper right')
    
    # è®¾ç½®åæ ‡è½´
    ax.set_xlim(-3.0, 3.0)
    ax.set_ylim(-3.0, 3.0)
    ax.set_xlabel('X (m)')
    ax.set_ylabel('Y (m)')
    ax.set_title('æœºæ¢°è‡‚æŠ•æ·ç»“æœå¯è§†åŒ–')
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    plt.close()

def visualize_angle_throws(target_angles, landing_positions, base_pos, save_path):
    """å¯è§†åŒ–è§’åº¦æ–¹å‘æŠ•æ·ç»“æœ"""
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # ç»˜åˆ¶æœºæ¢°è‡‚åŸºåº§ä½ç½®
    base = Circle((base_pos[0], base_pos[1]), 0.1, color='black', label='æœºæ¢°è‡‚åŸºåº§')
    ax.add_patch(base)
    
    # ç»˜åˆ¶æŠ•æ·ç»“æœ
    for i, (target_angle, landing) in enumerate(zip(target_angles, landing_positions)):
        # è®¡ç®—ç›®æ ‡æ–¹å‘ä¸Šçš„ä¸€ä¸ªç‚¹ï¼ˆç”¨äºæ˜¾ç¤ºç›®æ ‡æ–¹å‘ï¼‰
        target_distance = 3.0  # æ˜¾ç¤º3ç±³è·ç¦»çš„ç›®æ ‡æ–¹å‘
        target_x = base_pos[0] + target_distance * np.sin(target_angle)
        target_y = base_pos[1] + target_distance * np.cos(target_angle)
        
        # ç»˜åˆ¶ç›®æ ‡æ–¹å‘çº¿
        ax.plot([base_pos[0], target_x], [base_pos[1], target_y], 
                'g--', alpha=0.6, linewidth=2, label='ç›®æ ‡æ–¹å‘' if i == 0 else '')
        
        # ç»˜åˆ¶ç›®æ ‡æ–¹å‘ç‚¹
        ax.scatter(target_x, target_y, c='green', marker='x', s=150, alpha=0.8)
        
        # ç»˜åˆ¶å®é™…è½ç‚¹
        ax.scatter(landing[0], landing[1], c='red', marker='o', s=80, alpha=0.8)
        
        # ç»˜åˆ¶ä»åŸºåº§åˆ°è½ç‚¹çš„è¿çº¿
        ax.plot([base_pos[0], landing[0]], [base_pos[1], landing[1]], 
                'r-', alpha=0.4, linewidth=1)
        
        # è®¡ç®—å®é™…è§’åº¦
        direction_vector = landing - base_pos
        actual_angle = np.arctan2(direction_vector[0], direction_vector[1])
        
        # å°†å®é™…è§’åº¦è§„èŒƒåŒ–åˆ°[0, 2Ï€]èŒƒå›´ï¼Œä¸ç›®æ ‡è§’åº¦èŒƒå›´åŒ¹é…
        if actual_angle < 0:
            actual_angle += 2 * np.pi
        
        # è®¡ç®—è§’åº¦è¯¯å·®ï¼ˆè€ƒè™‘å‘¨æœŸæ€§ï¼‰
        angle_error = abs(actual_angle - target_angle)
        angle_error = min(angle_error, 2 * np.pi - angle_error)
        
        # æ·»åŠ è§’åº¦æ ‡æ³¨ï¼ˆä»…å‰å‡ ä¸ªï¼‰
        if i < 3:
            mid_x = (base_pos[0] + landing[0]) / 2
            mid_y = (base_pos[1] + landing[1]) / 2
            ax.annotate(f'è¯¯å·®:{np.degrees(angle_error):.1f}Â°', 
                       (mid_x, mid_y), fontsize=8, alpha=0.7)
    
    # æ·»åŠ è·ç¦»åœ†åœˆå‚è€ƒ
    for radius in [1, 2, 3]:
        circle = Circle((base_pos[0], base_pos[1]), radius, 
                       fill=False, color='gray', linestyle=':', alpha=0.3)
        ax.add_patch(circle)
        ax.text(base_pos[0] + radius, base_pos[1], f'{radius}m', 
               fontsize=8, alpha=0.5)
    
    # æ·»åŠ å›¾ä¾‹
    legend_handles = [
        mpatches.Patch(color='black', label='æœºæ¢°è‡‚åŸºåº§'),
        mpatches.Patch(color='green', label='ç›®æ ‡æ–¹å‘'),
        mpatches.Patch(color='red', label='å®é™…è½ç‚¹'),
        mpatches.Patch(color='gray', label='è·ç¦»å‚è€ƒåœ†')
    ]
    
    ax.legend(handles=legend_handles, loc='upper right')
    
    # è®¾ç½®åæ ‡è½´
    ax.set_xlim(-4.0, 4.0)
    ax.set_ylim(-4.0, 4.0)  # æ‰©å¤§Yè½´èŒƒå›´ä»¥æ˜¾ç¤ºåæ–¹æŠ•æ·
    ax.set_xlabel('X (m)')
    ax.set_ylabel('Y (m)')
    ax.set_title('æœºæ¢°è‡‚è§’åº¦æ–¹å‘æŠ•æ·ç»“æœå¯è§†åŒ– - åå‘æŠ•æ·æ¨¡å¼')
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    plt.close()

def visualize_distance_throws(landing_positions, base_pos, save_path):
    """å¯è§†åŒ–è¿œè·ç¦»å‰å‘æŠ•æ·ç»“æœ"""
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # ç»˜åˆ¶æœºæ¢°è‡‚åŸºåº§ä½ç½®
    base = Circle((base_pos[0], base_pos[1]), 0.1, color='black', label='æœºæ¢°è‡‚åŸºåº§')
    ax.add_patch(base)
    
    # ç»˜åˆ¶å‰å‘æ–¹å‘æŒ‡ç¤ºçº¿ï¼ˆ+Yè½´æ–¹å‘ï¼‰
    forward_line_length = 10.0  # 10ç±³é•¿çš„å‰å‘æŒ‡ç¤ºçº¿
    ax.arrow(base_pos[0], base_pos[1], 0, forward_line_length, 
             head_width=0.3, head_length=0.5, fc='blue', ec='blue', 
             alpha=0.7, linewidth=3, label='å‰å‘æ–¹å‘ (+Y)')
    
    # ç»˜åˆ¶ç›®æ ‡åŒºåŸŸï¼ˆ100ç±³è¿œï¼Œ50ç±³åå³çš„åŒºåŸŸï¼‰
    target_circle = Circle((base_pos[0] + 50, base_pos[1] + 100), 5.0, 
                          fill=False, color='green', linestyle='--', 
                          alpha=0.8, linewidth=2, label='ç›®æ ‡åŒºåŸŸ [100,50]')
    ax.add_patch(target_circle)
    
    # ç»˜åˆ¶æŠ•æ·ç»“æœ
    for i, landing in enumerate(landing_positions):
        # ç»˜åˆ¶å®é™…è½ç‚¹
        ax.scatter(landing[0], landing[1], c='red', marker='o', s=80, alpha=0.8)
        
        # ç»˜åˆ¶ä»åŸºåº§åˆ°è½ç‚¹çš„è¿çº¿
        ax.plot([base_pos[0], landing[0]], [base_pos[1], landing[1]], 
                'r-', alpha=0.4, linewidth=1)
        
        # è®¡ç®—æŠ•æ·è·ç¦»
        distance = np.linalg.norm(landing - base_pos)
        
        # æ·»åŠ è·ç¦»æ ‡æ³¨ï¼ˆä»…å‰å‡ ä¸ªï¼‰
        if i < 3:
            mid_x = (base_pos[0] + landing[0]) / 2
            mid_y = (base_pos[1] + landing[1]) / 2
            ax.annotate(f'{distance:.1f}m', 
                       (mid_x, mid_y), fontsize=8, alpha=0.7,
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.7))
    
    # æ·»åŠ è·ç¦»åœ†åœˆå‚è€ƒ
    for radius in [10, 20, 50, 100]:
        circle = Circle((base_pos[0], base_pos[1]), radius, 
                       fill=False, color='gray', linestyle=':', alpha=0.3)
        ax.add_patch(circle)
        ax.text(base_pos[0] + radius * 0.7, base_pos[1] + radius * 0.7, f'{radius}m', 
               fontsize=8, alpha=0.5)
    
    # æ·»åŠ å›¾ä¾‹
    legend_handles = [
        mpatches.Patch(color='black', label='æœºæ¢°è‡‚åŸºåº§'),
        mpatches.Patch(color='blue', label='å‰å‘æ–¹å‘ (+Y)'),
        mpatches.Patch(color='green', label='ç›®æ ‡åŒºåŸŸ (100m)'),
        mpatches.Patch(color='red', label='å®é™…è½ç‚¹'),
        mpatches.Patch(color='gray', label='è·ç¦»å‚è€ƒåœ†')
    ]
    
    ax.legend(handles=legend_handles, loc='upper right')
    
    # è®¾ç½®åæ ‡è½´
    max_distance = max([np.linalg.norm(pos - base_pos) for pos in landing_positions])
    axis_limit = max(max_distance * 1.2, 120)  # è‡³å°‘æ˜¾ç¤º120ç±³
    
    ax.set_xlim(-axis_limit * 0.3, axis_limit * 0.3)
    ax.set_ylim(-axis_limit * 0.1, axis_limit)
    ax.set_xlabel('X (m)')
    ax.set_ylabel('Y (m)')
    ax.set_title('æœºæ¢°è‡‚è¿œè·ç¦»åå³å‰æ–¹æŠ•æ·ç»“æœå¯è§†åŒ– [100,50]')
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    plt.close()

def visualize_joint_trajectories(joint_trajectories, control_freq, save_path, episode_info, position_targets=None):
    """Visualize joint angle trajectories over time - overlapping plot with P targets"""
    if not joint_trajectories:
        print("âš ï¸  No joint trajectory data available for visualization")
        return
    
    # Joint name mapping
    joint_names = [
        "Rotation_R (Shoulder Pan)",
        "Pitch_R (Shoulder Lift)", 
        "Elbow_R (Elbow Flex)",
        "Wrist_Pitch_R (Wrist Flex)",
        "Wrist_Roll_R (Wrist Roll)"
    ]
    joint_colors = ['blue', 'red', 'green', 'orange', 'purple']
    
    # Create time axis
    time_steps = np.arange(len(joint_trajectories)) / control_freq  # Convert to seconds
    
    # Extract angle data for each joint (convert from radians to degrees)
    joint_data = np.array(joint_trajectories)  # [timesteps, joints]
    joint_data_deg = np.degrees(joint_data)
    
    # Create figure with two subplots: one for overlapping trajectories, one for P targets
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))
    fig.suptitle(f'Episode 0 Joint Trajectories - Long-distance Forward Throw\n'
                f'Throw Distance: {episode_info.get("throw_distance", 0):.2f}m, '
                f'Forward Deviation: {np.degrees(episode_info.get("direction_error", 0)):.1f}Â°, '
                f'Throw Velocity: {episode_info.get("throw_velocity", 0):.2f}m/s', 
                fontsize=14, fontweight='bold')
    
    # Plot 1: All joint angles overlapping
    ax1.set_title('Joint Angle Trajectories (Actual Positions)', fontsize=12, fontweight='bold')
    
    for i in range(5):  # 5 joints
        ax1.plot(time_steps, joint_data_deg[:, i], 
                color=joint_colors[i], linewidth=2, 
                label=f'{joint_names[i]}', alpha=0.8)
    
    ax1.set_xlabel('Time (s)')
    ax1.set_ylabel('Angle (deg)')
    ax1.grid(True, alpha=0.3)
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Add throw detection marker if available
    throw_step = episode_info.get("throw_step", None)
    if throw_step is not None:
        throw_time = throw_step / control_freq
        ax1.axvline(x=throw_time, color='red', linestyle='--', alpha=0.7, 
                   label=f'Throw Detection ({throw_time:.2f}s)')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Calculate and display joint motion statistics
    motion_stats = []
    for i, name in enumerate(joint_names):
        min_angle = np.min(joint_data_deg[:, i])
        max_angle = np.max(joint_data_deg[:, i])
        range_angle = max_angle - min_angle
        mean_angle = np.mean(joint_data_deg[:, i])
        motion_stats.append(f"{name.split('(')[0].strip()}: Range={range_angle:.1f}Â°, Mean={mean_angle:.1f}Â°")
    
    # Add statistics text box
    stats_text = "Joint Motion Statistics:\n" + "\n".join([f"â€¢ {stat}" for stat in motion_stats])
    ax1.text(0.02, 0.98, stats_text, transform=ax1.transAxes, 
            verticalalignment='top', fontsize=9,
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
    
    # Plot 2: Position targets (P targets) - actual targets sent to robot
    ax2.set_title('Joint Position Targets (Policy Output + Default Positions)', fontsize=12, fontweight='bold')
    
    if position_targets is not None and len(position_targets) > 0:
        # Use actual recorded position targets
        target_data = np.array(position_targets)  # [timesteps, joints]
        target_data_deg = np.degrees(target_data)
        
        # Ensure time_steps and target_data have the same length
        min_length = min(len(time_steps), len(target_data_deg))
        time_steps_targets = time_steps[:min_length]
        target_data_deg = target_data_deg[:min_length]
        
        for i in range(5):  # 5 joints
            ax2.plot(time_steps_targets, target_data_deg[:, i], 
                    color=joint_colors[i], linewidth=2, linestyle='--',
                    label=f'{joint_names[i]} Target', alpha=0.8)
    else:
        # Fallback: Simulate position targets using smoothed version of joint trajectories
        print("âš ï¸  No position target data available, using simulated targets")
        
        # Use simple moving average for fallback
        window_size = 5
        for i in range(5):  # 5 joints
            if len(joint_data_deg) >= window_size:
                smoothed_trajectory = np.convolve(joint_data_deg[:, i], 
                                                np.ones(window_size)/window_size, mode='same')
            else:
                smoothed_trajectory = joint_data_deg[:, i]
            
            ax2.plot(time_steps, smoothed_trajectory, 
                    color=joint_colors[i], linewidth=2, linestyle='--',
                    label=f'{joint_names[i]} Target (Simulated)', alpha=0.8)
    
    ax2.set_xlabel('Time (s)')
    ax2.set_ylabel('Target Angle (deg)')
    ax2.grid(True, alpha=0.3)
    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Add throw detection marker to P target plot as well
    if throw_step is not None:
        ax2.axvline(x=throw_time, color='red', linestyle='--', alpha=0.7, 
                   label=f'Throw Detection ({throw_time:.2f}s)')
        ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Add episode performance summary
    performance_text = f"""Episode Performance Summary:
â€¢ Total Duration: {len(joint_trajectories) / control_freq:.2f} seconds
â€¢ Control Frequency: {control_freq} Hz
â€¢ Total Steps: {len(joint_trajectories)}
â€¢ Throw Distance: {episode_info.get("throw_distance", 0):.3f} m
â€¢ Forward Deviation: {np.degrees(episode_info.get("direction_error", 0)):.1f}Â°
â€¢ Throw Velocity: {episode_info.get("throw_velocity", 0):.2f} m/s
â€¢ Episode Reward: {episode_info.get("episode_reward", 0):.1f}
â€¢ Direction Success: {'Yes' if episode_info.get("direction_success", False) else 'No'}
â€¢ Distance Success: {'Yes' if episode_info.get("distance_success", False) else 'No'}
â€¢ Overall Success: {'Yes' if episode_info.get("overall_success", False) else 'No'}"""
    
    ax2.text(0.02, 0.02, performance_text, transform=ax2.transAxes, 
            verticalalignment='bottom', fontsize=9,
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen", alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“ˆ Joint angle trajectory visualization saved at: {save_path}")

def get_cfgs():
    """è·å–è¯„ä¼°é…ç½® - è¿œè·ç¦»å‰å‘æŠ•æ·æ¨¡å¼"""
    # ç¯å¢ƒé…ç½®ï¼ˆä»è®­ç»ƒè„šæœ¬åŒæ­¥ï¼‰
    env_cfg = {
        "num_actions": 5,  # 5ä¸ªå…³èŠ‚
        "robot_file": "/home/nvidiapc/dodo/Genesis/genesis/assets/xml/le_simulation/simulation/single_le_box.xml",
        "joint_names": [
            "Rotation_R",
            "Pitch_R", 
            "Elbow_R",
            "Wrist_Pitch_R",
            "Wrist_Roll_R"
        ],
        "default_joint_angles": [0.0, 3.14, 0.0, 0.0, 3.14],  # ä¿æŒåˆå§‹å…³èŠ‚ä½ç½®
        "kp": 50.0,  # å›ºå®šä½ç½®å¢ç›Š
        "kd": 5.0,   # é€Ÿåº¦å¢ç›Š
        "torque_limit": 35.0,  # åŠ›çŸ©é™åˆ¶
        "episode_length_s": 5.0,  # episodeé•¿åº¦
        "control_freq": 50,  # æ§åˆ¶é¢‘ç‡50Hz
        "action_scale": 0.7,  # åŠ¨ä½œç¼©æ”¾
        "clip_actions": 1.2,  # åŠ¨ä½œè£å‰ªèŒƒå›´
        "freeze_duration_s": 0.4,  # å†»ç»“æ—¶é—´
    }
    
    # è§‚æµ‹é…ç½® - è¿œè·ç¦»å‰å‘æŠ•æ·
    obs_cfg = {
        "num_obs": 5 + 5,  # å…³èŠ‚ä½ç½®(5) + å…³èŠ‚é€Ÿåº¦(5)ï¼Œç§»é™¤ç›®æ ‡è§’åº¦
        "obs_scales": {
            "dof_pos": 1.0,      # å…³èŠ‚ä½ç½®
            "dof_vel": 0.05,     # å…³èŠ‚é€Ÿåº¦
        },
    }
    
    # å¥–åŠ±é…ç½® - è¿œè·ç¦»å‰å‘æŠ•æ·è®­ç»ƒï¼ˆæ¿€è¿›æ¨¡å¼ï¼Œä¸è®­ç»ƒè„šæœ¬ä¸€è‡´ï¼‰
    reward_cfg = {
        "target_throw_position": [100.0, 0.0],  # ç›®æ ‡æŠ•æ·ä½ç½®
        "distance_tolerance": 5.0,  # è·ç¦»å®¹å¿åº¦
        "direction_tolerance": 0.3,  # æ–¹å‘å®¹å¿åº¦
        "reward_scales": {
            # ä¸»è¦å¥–åŠ± - è¿œè·ç¦»æŠ•æ·ï¼ˆå¤§å¹…å¢å¼ºï¼‰
            "throw_distance_reward": 5000.0,  # æŠ•æ·è·ç¦»å¥–åŠ±ï¼ˆè¶Šè¿œè¶Šå¥½ï¼‰- å¢å¼º2.5å€
            "forward_direction_reward": 3000.0,  # å‰å‘æ–¹å‘å¥–åŠ± - å¢å¼º2å€
            "throw_success": 800.0,  # åŸºæœ¬æŠ•æ·æˆåŠŸå¥–åŠ± - å¢å¼º
            "velocity_magnitude_reward": 1200.0,  # çƒåˆå§‹é€Ÿåº¦å¥–åŠ± - å¢å¼º50%
            
            # ç‰¹æ®Šå¥–åŠ± - é¼“åŠ±Rotation_Rå…³èŠ‚ä½¿ç”¨ä»¥ç„å‡†[100, 50]
            "rotation_r_usage_reward": 2000.0,  # é¼“åŠ±ä½¿ç”¨Rotation_Rå…³èŠ‚è¿›è¡Œä¾§å‘ç„å‡†
            "target_alignment_reward": 2500.0,  # å¥–åŠ±ç„å‡†æ­£ç¡®ç›®æ ‡æ–¹å‘[100, 50]
            
            # ç§»é™¤çº¦æŸï¼Œé¼“åŠ±æ‰€æœ‰å…³èŠ‚è‡ªç”±è¿åŠ¨
            # "wrist_roll_lock": 0.0,  # å®Œå…¨ç§»é™¤æ‰‹è…•æ»šè½¬é”å®šï¼Œå…è®¸è‡ªç”±æ‰­è½¬
            "joint_vel_penalty": 0.005,  # å¤§å¹…å‡å°‘å…³èŠ‚é€Ÿåº¦æƒ©ç½šï¼Œé¼“åŠ±å¿«é€Ÿè¿åŠ¨
            "action_smoothness": 0.05,   # å‡å°‘åŠ¨ä½œå¹³æ»‘åº¦æƒ©ç½šï¼Œå…è®¸æ›´æ¿€è¿›çš„åŠ¨ä½œ
            "energy_penalty": 0.002,   # å‡å°‘èƒ½è€—æƒ©ç½šï¼Œé¼“åŠ±å¤§åŠ›æŠ•æ·
        },
    }
    
    # å‘½ä»¤é…ç½® - å›ºå®šåå³å‰æ–¹æŠ•æ·ç›®æ ‡
    command_cfg = {
        "num_commands": 0,  # ä¸éœ€è¦å‘½ä»¤ï¼Œç›®æ ‡å›ºå®š
        "target_position": [100.0, 50.0],  # å›ºå®šç›®æ ‡ï¼š100ç±³è¿œï¼Œ50ç±³åå³ï¼ˆé¼“åŠ±Rotation_Rä½¿ç”¨ï¼‰
        "training_mode": "max_distance_forward",  # è®­ç»ƒæ¨¡å¼æ ‡è¯†
    }
    
    return env_cfg, obs_cfg, reward_cfg, command_cfg

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("-e", "--exp_name", type=str, default="so_arm_throwing")
    parser.add_argument("--ckpt", type=int, default=700, help="æ£€æŸ¥ç‚¹ç¼–å·ï¼Œ-1è¡¨ç¤ºæœ€ç»ˆæ¨¡å‹")
    parser.add_argument("--num_episodes", type=int, default=10, help="è¯„ä¼°çš„episodeæ•°é‡")
    # ç§»é™¤è§’åº¦å‚æ•°ï¼Œå› ä¸ºç›®æ ‡å›ºå®šä¸ºå‰å‘æŠ•æ·
    parser.add_argument("--visualize", action="store_true", default=True, help="å¯è§†åŒ–æŠ•æ·ç»“æœ")
    parser.add_argument("--record", action="store_true", help="è®°å½•å…³èŠ‚è§’åº¦åºåˆ—ç”¨äºçœŸå®æœºå™¨äººæ§åˆ¶")
    parser.add_argument("--record_type", type=str, default="target", choices=["target", "state"], 
                       help="è®°å½•ç±»å‹: 'target'=ç›®æ ‡å…³èŠ‚è§’åº¦(NNè¾“å‡º), 'state'=å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€")
    parser.add_argument("--record_episode", type=int, default=0, help="æŒ‡å®šè¦è®°å½•çš„episodeç¼–å·ï¼ˆ0-basedï¼‰")
    args = parser.parse_args()
    
    # åˆå§‹åŒ–Genesis
    gs.init(logging_level="warning")
    
    # åŠ è½½é…ç½®
    log_dir = f"../../logs/{args.exp_name}"  # ä¿®æ­£è·¯å¾„ï¼šä»examples/le/åˆ°Genesisæ ¹ç›®å½•
    if not os.path.exists(log_dir):
        print(f"âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {log_dir}")
        print(f"è¯·å…ˆè¿è¡Œè®­ç»ƒ: python le_train.py -e {args.exp_name}")
        return
    
    try:
        # å¯¹äºè§’åº¦æ–¹å‘è®­ç»ƒï¼Œä½¿ç”¨å†…ç½®é…ç½®è€Œä¸æ˜¯ä»æ–‡ä»¶åŠ è½½
        env_cfg, obs_cfg, reward_cfg, command_cfg = get_cfgs()
        
        # å°è¯•ä»è®­ç»ƒé…ç½®æ–‡ä»¶è·å–train_cfgï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            _, _, _, _, train_cfg = pickle.load(open(f"{log_dir}/cfgs.pkl", "rb"))
        except:
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çš„train_cfg
            train_cfg = {
                "policy": {
                    "activation": "elu",
                    "actor_hidden_dims": [256, 128, 64],
                    "critic_hidden_dims": [256, 128, 64],
                    "init_noise_std": 1.5,
                    "class_name": "ActorCritic",
                },
                "algorithm": {
                    "class_name": "PPO",
                    "clip_param": 0.2,
                    "desired_kl": 0.01,
                    "entropy_coef": 0.03,
                    "gamma": 0.97,
                    "lam": 0.95,
                    "learning_rate": 0.0008,
                    "max_grad_norm": 1.0,
                    "num_learning_epochs": 5,
                    "num_mini_batches": 4,
                    "schedule": "adaptive",
                    "use_clipped_value_loss": True,
                    "value_loss_coef": 1.0,
                },
                "init_member_classes": {},
                "runner": {
                    "checkpoint": -1,
                    "experiment_name": args.exp_name,
                    "load_run": -1,
                    "log_interval": 1,
                    "max_iterations": 700,
                    "record_interval": -1,
                    "resume": False,
                    "resume_path": None,
                    "run_name": "",
                },
                "runner_class_name": "OnPolicyRunner",
                "num_steps_per_env": 32,
                "save_interval": 50,
                "empirical_normalization": None,
                "seed": 1,
                "logger": "tensorboard",
                "tensorboard_subdir": "tb",
            }
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"è¿œè·ç¦»å‰å‘æŠ•æ·è¯„ä¼°é…ç½® - {args.exp_name}")
    print(f"{'='*60}")
    print(f"Episodeæ•°é‡: {args.num_episodes}")
    print(f"æ§åˆ¶é¢‘ç‡: {env_cfg['control_freq']} Hz")
    print(f"Episodeé•¿åº¦: {env_cfg['episode_length_s']} ç§’")
    print(f"è§‚æµ‹ç»´åº¦: {obs_cfg['num_obs']} (å…³èŠ‚çŠ¶æ€)")
    print(f"På¢ç›Š: {env_cfg['kp']} (å›ºå®šå€¼)")
    
    if args.record:
        record_type_desc = "ç›®æ ‡å…³èŠ‚è§’åº¦(NNè¾“å‡º)" if args.record_type == "target" else "å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€"
        print(f"ğŸ¬ è®°å½•æ¨¡å¼: å¯ç”¨ (è®°å½•episode {args.record_episode}, ç±»å‹: {record_type_desc})")
    
    target_pos = command_cfg["target_position"]
    print(f"æŠ•æ·ç›®æ ‡: [{target_pos[0]:.0f}, {target_pos[1]:.0f}]ç±³ (è¿œè·ç¦»å‰å‘æŠ•æ·)")
    print(f"è®­ç»ƒæ¨¡å¼: {command_cfg['training_mode']}")
    print(f"æ–¹å‘å®¹å¿åº¦: {reward_cfg['direction_tolerance']:.2f} å¼§åº¦ ({np.degrees(reward_cfg['direction_tolerance']):.1f}Â°)")
    print(f"è·ç¦»å®¹å¿åº¦: {reward_cfg['distance_tolerance']:.1f}m")
    print(f"{'='*60}")
    
    # åˆ›å»ºç¯å¢ƒï¼ˆå•ä¸ªç¯å¢ƒç”¨äºè¯„ä¼°ï¼‰
    env = SoArmEnv(
        num_envs=1,
        env_cfg=env_cfg,
        obs_cfg=obs_cfg,
        reward_cfg=reward_cfg,
        command_cfg=command_cfg,
        show_viewer=True,
    )
    
    # æ·»åŠ çº¢è‰²çƒä½“ä½œä¸ºå¯è§†åŒ–æŒ‡ç¤ºå™¨
    print("ğŸ”´ æ·»åŠ å¯è§†åŒ–æŒ‡ç¤ºå™¨çƒä½“åˆ°ä½ç½® [1, 0, 1.2]")
    try:
        # ä½¿ç”¨MJCFæ–¹å¼åˆ›å»ºçƒä½“
        indicator_ball = env.scene.add_entity(
            gs.morphs.MJCF(
                xml_string="""
                <mujoco>
                    <worldbody>
                        <body name="indicator_ball" pos="1.0 0.0 1.2">
                            <geom type="sphere" size="0.05" rgba="1 0 0 1" contype="0" conaffinity="0"/>
                        </body>
                    </worldbody>
                </mujoco>
                """
            )
        )
        print("âœ… çº¢è‰²æŒ‡ç¤ºå™¨çƒä½“æ·»åŠ å®Œæˆ (MJCFæ–¹å¼)")
    except Exception as e:
        print(f"âš ï¸  MJCFæ–¹å¼å¤±è´¥ï¼Œå°è¯•Boxæ–¹å¼: {e}")
        try:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨Boxåˆ›å»ºå°ç«‹æ–¹ä½“ä½œä¸ºæŒ‡ç¤ºå™¨
            indicator_ball = env.scene.add_entity(
                gs.morphs.Box(
                    pos=(1.0, 0.0, 1.2),
                    size=(0.05, 0.05, 0.05),
                    color=(1.0, 0.0, 0.0, 1.0),  # çº¢è‰²
                    fixed=True
                )
            )
            print("âœ… çº¢è‰²æŒ‡ç¤ºå™¨ç«‹æ–¹ä½“æ·»åŠ å®Œæˆ (Boxæ–¹å¼)")
        except Exception as e2:
            print(f"âŒ æŒ‡ç¤ºå™¨æ·»åŠ å¤±è´¥: {e2}")
            print("ğŸ’¡ ç»§ç»­è¿è¡Œï¼Œä½†æ²¡æœ‰å¯è§†åŒ–æŒ‡ç¤ºå™¨")
    
    # åŠ è½½è®­ç»ƒå™¨å’Œç­–ç•¥
    runner = OnPolicyRunner(env, train_cfg, log_dir, device=gs.device)
    
    # åŠ è½½æ¨¡å‹
    ckpt_name = f"model_{args.ckpt}.pt" if args.ckpt >= 0 else "model_final.pt"
    model_path = os.path.join(log_dir, ckpt_name)
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        # å°è¯•æŸ¥æ‰¾å¯ç”¨çš„æ£€æŸ¥ç‚¹
        available_ckpts = []
        for f in os.listdir(log_dir):
            if f.startswith("model_") and f.endswith(".pt"):
                available_ckpts.append(f)
        if available_ckpts:
            print(f"å¯ç”¨çš„æ£€æŸ¥ç‚¹: {', '.join(available_ckpts)}")
        return
    
    print(f"ğŸ“ åŠ è½½æ¨¡å‹: {model_path}")
    runner.load(model_path)
    
    # è·å–æ¨ç†ç­–ç•¥
    policy = runner.get_inference_policy(device=gs.device)
    
    # è¯„ä¼°ç»Ÿè®¡ - è¿œè·ç¦»å‰å‘æŠ•æ·
    episode_rewards = []
    throw_distances = []
    direction_errors = []  # å‰å‘æ–¹å‘è¯¯å·®ç»Ÿè®¡
    throw_velocities = []  # æŠ•æ·é€Ÿåº¦ç»Ÿè®¡
    landing_positions = []
    success_rates = []
    
    # è®°å½•å˜é‡
    recorded_joint_sequence = []
    recorded_episode_info = {}
    
    # Episode 0çš„å…³èŠ‚è½¨è¿¹è®°å½•ï¼ˆæ€»æ˜¯è®°å½•ï¼Œç”¨äºå¯è§†åŒ–ï¼‰
    episode_0_joint_trajectory = []
    episode_0_info = {}
    
    print(f"\nğŸš€ å¼€å§‹è¯„ä¼° {args.num_episodes} ä¸ªepisodes...")
    
    # ä¸»è¯„ä¼°å¾ªç¯
    for episode in range(args.num_episodes):
        obs, _ = env.reset()
        
        # å›ºå®šç›®æ ‡ï¼š100ç±³è¿œï¼Œæ­£å‰æ–¹
        target_position = command_cfg["target_position"]
        
        episode_reward = 0
        max_ball_height = env.ball_init_pos[2]
        throw_detected = False
        throw_velocity = 0.0
        throw_step = None
        
        # å½“å‰episodeçš„å…³èŠ‚è§’åº¦åºåˆ—
        current_episode_joints = []
        # Episode 0çš„åŸå§‹å…³èŠ‚è§’åº¦è½¨è¿¹ï¼ˆå¼§åº¦ï¼‰
        current_episode_joint_trajectory = []
        # Episode 0çš„ä½ç½®ç›®æ ‡è½¨è¿¹ï¼ˆPç›®æ ‡ï¼Œå¼§åº¦ï¼‰
        current_episode_position_targets = []
        
        print(f"\nğŸ“ Episode {episode + 1}:")
        print(f"  æŠ•æ·ç›®æ ‡: [{target_position[0]:.0f}, {target_position[1]:.0f}]ç±³ (è¿œè·ç¦»å‰å‘æŠ•æ·)")
        print(f"  å½“å‰På¢ç›Š: {env_cfg['kp']} (å›ºå®šå€¼)")
        
        if args.record and episode == args.record_episode:
            record_desc = "ç›®æ ‡å…³èŠ‚è§’åº¦" if args.record_type == "target" else "å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€"
            print(f"  ğŸ¬ æ­£åœ¨è®°å½•æ­¤episodeçš„{record_desc}åºåˆ—...")
        
        if episode == 0:
            print(f"  ğŸ“ˆ æ­£åœ¨è®°å½•Episode 0çš„å…³èŠ‚è§’åº¦è½¨è¿¹ç”¨äºå¯è§†åŒ–...")
        
        with torch.no_grad():
            while True:
                # è·å–åŠ¨ä½œ
                actions = policy(obs)
                
                # è®°å½•å…³èŠ‚è§’åº¦åºåˆ—ï¼ˆå¦‚æœæ˜¯æŒ‡å®šçš„è®°å½•episodeï¼‰
                if args.record and episode == args.record_episode:
                    if args.record_type == "target":
                        # è®°å½•ç›®æ ‡å…³èŠ‚è§’åº¦ï¼ˆNNè¾“å‡ºè®¡ç®—çš„ç›®æ ‡ä½ç½®ï¼‰
                        is_frozen = env.freeze_counter[0] > 0
                        if is_frozen:
                            # å†»ç»“æœŸé—´ä½¿ç”¨é»˜è®¤å§¿æ€
                            joint_angles = env.default_dof_pos.cpu().numpy()
                        else:
                            # æ­£å¸¸æœŸé—´ä½¿ç”¨ç­–ç•¥åŠ¨ä½œè®¡ç®—ç›®æ ‡ä½ç½®
                            joint_angles = (actions[0] * env.env_cfg["action_scale"] + env.default_dof_pos).cpu().numpy()
                        
                        # æ˜ å°„åˆ°çœŸå®æœºå™¨äººå…³èŠ‚è§’åº¦å¹¶è®°å½•
                        robot_angles = map_joint_angles_to_robot(joint_angles)
                        current_episode_joints.append(robot_angles)
                
                # æ‰§è¡ŒåŠ¨ä½œ
                obs, rews, dones, infos = env.step(actions)
                
                # è®°å½•Episode 0çš„å…³èŠ‚è½¨è¿¹ï¼ˆåŸå§‹å¼§åº¦å€¼ï¼‰å’Œä½ç½®ç›®æ ‡
                if episode == 0:
                    current_joint_angles = env.dof_pos[0].cpu().numpy()
                    current_episode_joint_trajectory.append(current_joint_angles.copy())
                    
                    # è®°å½•ä½ç½®ç›®æ ‡ï¼ˆPç›®æ ‡ï¼‰- è®¡ç®—å‘é€ç»™æœºå™¨äººçš„å®é™…ç›®æ ‡ä½ç½®
                    is_frozen = env.freeze_counter[0] > 0
                    if is_frozen:
                        # å†»ç»“æœŸé—´ä½¿ç”¨é»˜è®¤å§¿æ€ä½œä¸ºç›®æ ‡
                        position_targets = env.default_dof_pos.cpu().numpy()
                    else:
                        # æ­£å¸¸æœŸé—´ä½¿ç”¨ç­–ç•¥åŠ¨ä½œè®¡ç®—ç›®æ ‡ä½ç½®
                        position_targets = (actions[0] * env.env_cfg["action_scale"] + env.default_dof_pos).cpu().numpy()
                    
                    current_episode_position_targets.append(position_targets.copy())
                
                # è®°å½•å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€ï¼ˆåœ¨stepä¹‹åï¼Œè·å–æ‰§è¡Œåçš„å®é™…çŠ¶æ€ï¼‰
                if args.record and episode == args.record_episode and args.record_type == "state":
                    # è®°å½•å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€
                    actual_joint_angles = env.dof_pos[0].cpu().numpy()
                    
                    # æ˜ å°„åˆ°çœŸå®æœºå™¨äººå…³èŠ‚è§’åº¦å¹¶è®°å½•
                    robot_angles = map_joint_angles_to_robot(actual_joint_angles)
                    current_episode_joints.append(robot_angles)
                episode_reward += rews[0].item()
                
                # æ›´æ–°æœ€å¤§çƒé«˜åº¦å’ŒæŠ•æ·æ£€æµ‹
                current_ball_height = env.ball_pos[0, 2].item()
                max_ball_height = max(max_ball_height, current_ball_height)
                if not throw_detected and env.throw_detected[0]:
                    throw_detected = True
                    throw_step = env.episode_length_buf[0].item()
                    # è®°å½•æŠ•æ·é€Ÿåº¦
                    throw_velocity = env.throw_velocity_magnitude[0].item()
                    print(f"  ğŸ€ æŠ•æ·æ£€æµ‹! æ­¥æ•°: {env.episode_length_buf[0]}, æŠ•æ·é€Ÿåº¦: {throw_velocity:.2f}m/s")
                
                # æ‰“å°çŠ¶æ€ä¿¡æ¯ï¼ˆæ¯50æ­¥ï¼‰
                if env.episode_length_buf[0] % 50 == 0:
                    ball_pos = env.ball_pos[0].cpu().numpy()
                    freeze_remaining = max(0, env.freeze_counter[0].item() * env.dt)
                    status = f"å†»ç»“ä¸­({freeze_remaining:.1f}s)" if freeze_remaining > 0 else "è¿è¡Œä¸­"
                    print(f"  æ­¥æ•°: {env.episode_length_buf[0]}, çƒä½ç½®: ({ball_pos[0]:.2f}, {ball_pos[1]:.2f}, {ball_pos[2]:.2f}), çŠ¶æ€: {status}")
                
                # Episodeç»“æŸ
                if dones[0]:
                    # è·å–è½ç‚¹ä½ç½®
                    landing_pos = env.ball_landing_pos[0].cpu().numpy()
                    landing_positions.append(landing_pos.copy())
                    
                    # è®¡ç®—æŠ•æ·è·ç¦»ï¼ˆä»åŸºåº§åˆ°è½ç‚¹ï¼‰
                    base_pos = env.base_pos[:2].cpu().numpy()
                    throw_dist = np.linalg.norm(landing_pos - base_pos)
                    throw_distances.append(throw_dist)
                    
                    # è®¡ç®—å‰å‘æ–¹å‘åå·®
                    direction_vector = landing_pos - base_pos
                    direction_norm = np.linalg.norm(direction_vector)
                    
                    if direction_norm > 0.1:  # é¿å…é™¤é›¶
                        # å½’ä¸€åŒ–æ–¹å‘å‘é‡
                        normalized_direction = direction_vector / direction_norm
                        # å‰å‘æ–¹å‘æ˜¯+Yè½´
                        forward_direction = np.array([0.0, 1.0])
                        # è®¡ç®—ä¸å‰å‘æ–¹å‘çš„è§’åº¦åå·®
                        cos_similarity = np.dot(normalized_direction, forward_direction)
                        direction_error = np.arccos(np.clip(cos_similarity, -1.0, 1.0))  # 0åˆ°Ï€çš„è§’åº¦åå·®
                    else:
                        direction_error = np.pi  # æœ€å¤§åå·®
                    
                    direction_errors.append(float(direction_error))
                    throw_velocities.append(throw_velocity)
                    
                    # è®¡ç®—æˆåŠŸç‡ï¼ˆåŸºäºæ–¹å‘å’Œè·ç¦»ï¼‰
                    direction_tolerance = reward_cfg.get("direction_tolerance", 0.3)
                    distance_tolerance = reward_cfg.get("distance_tolerance", 5.0)
                    direction_success = direction_error <= direction_tolerance
                    distance_success = throw_dist >= 1.0  # è‡³å°‘æŠ•æ·1ç±³
                    overall_success = direction_success and distance_success
                    success_rates.append(overall_success)
                    
                    print(f"  ğŸ“ çƒè½åœ°ä½ç½®: ({landing_pos[0]:.3f}, {landing_pos[1]:.3f})")
                    print(f"  ğŸ“ æŠ•æ·è·ç¦»: {throw_dist:.3f}m")
                    print(f"  ğŸ“ å‰å‘åå·®: {np.degrees(direction_error):.1f}Â° (å®¹å¿åº¦: {np.degrees(direction_tolerance):.1f}Â°)")
                    print(f"  ğŸš€ æŠ•æ·é€Ÿåº¦: {throw_velocity:.2f}m/s")
                    print(f"  ğŸ“ˆ æœ€å¤§çƒé«˜åº¦: {max_ball_height:.3f}m")
                    print(f"  ğŸ† Episodeå¥–åŠ±: {episode_reward:.2f}")
                    print(f"  ğŸ¯ æ–¹å‘æˆåŠŸ: {'âœ…' if direction_success else 'âŒ'}")
                    print(f"  ğŸ¯ è·ç¦»æˆåŠŸ: {'âœ…' if distance_success else 'âŒ'} (â‰¥1.0m)")
                    print(f"  ğŸ¯ ç»¼åˆæˆåŠŸ: {'âœ…' if overall_success else 'âŒ'}")
                    print(f"  ğŸ² æŠ•æ·æ£€æµ‹: {'æ˜¯' if throw_detected else 'å¦'}")
                    
                    # ä¿å­˜Episode 0çš„è½¨è¿¹ä¿¡æ¯
                    if episode == 0:
                        episode_0_joint_trajectory = current_episode_joint_trajectory
                        episode_0_position_targets = current_episode_position_targets
                        episode_0_info = {
                            "episode": episode,
                            "target_position": target_position,
                            "direction_error": float(direction_error),
                            "throw_velocity": float(throw_velocity),
                            "landing_pos": landing_pos.tolist(),
                            "episode_reward": float(episode_reward),
                            "throw_distance": float(throw_dist),
                            "max_ball_height": float(max_ball_height),
                            "throw_detected": bool(throw_detected),
                            "throw_step": throw_step,
                            "total_steps": len(current_episode_joint_trajectory),
                            "direction_success": bool(direction_success),
                            "distance_success": bool(distance_success),
                            "overall_success": bool(overall_success),
                            "position_targets": episode_0_position_targets  # æ·»åŠ ä½ç½®ç›®æ ‡æ•°æ®
                        }
                        print(f"  ğŸ“ˆ å·²è®°å½•Episode 0å…³èŠ‚è½¨è¿¹: {len(current_episode_joint_trajectory)} æ­¥")
                        print(f"  ğŸ“ˆ å·²è®°å½•Episode 0ä½ç½®ç›®æ ‡: {len(current_episode_position_targets)} æ­¥")
                    
                    # ä¿å­˜è®°å½•çš„å…³èŠ‚åºåˆ—
                    if args.record and episode == args.record_episode:
                        recorded_joint_sequence = current_episode_joints
                        recorded_episode_info = {
                            "episode": episode,
                            "target_position": target_position,
                            "direction_error": float(direction_error),
                            "throw_velocity": float(throw_velocity),
                            "landing_pos": landing_pos.tolist(),
                            "episode_reward": float(episode_reward),
                            "throw_distance": float(throw_dist),
                            "max_ball_height": float(max_ball_height),
                            "throw_detected": bool(throw_detected),
                            "total_steps": len(current_episode_joints),
                            "direction_success": bool(direction_success),
                            "distance_success": bool(distance_success),
                            "overall_success": bool(overall_success)
                        }
                        record_desc = "ç›®æ ‡å…³èŠ‚è§’åº¦" if args.record_type == "target" else "å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€"
                        print(f"  ğŸ¬ å·²è®°å½• {len(current_episode_joints)} æ­¥{record_desc}åºåˆ—")
                    
                    episode_rewards.append(episode_reward)
                    break
    
    # ä¿å­˜è®°å½•çš„å…³èŠ‚åºåˆ—
    if args.record and recorded_joint_sequence:
        # ä¿å­˜ä¸ºJSONæ ¼å¼
        record_data = {
            "episode_info": recorded_episode_info,
            "joint_sequence": recorded_joint_sequence,
            "record_type": args.record_type,
            "record_description": {
                "target": "ç›®æ ‡å…³èŠ‚è§’åº¦åºåˆ— - ç¥ç»ç½‘ç»œè¾“å‡ºè®¡ç®—çš„ç›®æ ‡ä½ç½®ï¼Œå‘é€ç»™æœºå™¨äººçš„æ§åˆ¶å‘½ä»¤",
                "state": "å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€åºåˆ— - æœºå™¨äººæ‰§è¡Œåçš„å®é™…å…³èŠ‚ä½ç½®ï¼Œåæ˜ çœŸå®è¿åŠ¨è½¨è¿¹"
            }[args.record_type],
            "joint_mapping": {
                "simulation": ["Rotation_R", "Pitch_R", "Elbow_R", "Wrist_Pitch_R", "Wrist_Roll_R"],
                "robot": ["shoulder_pan.pos", "shoulder_lift.pos", "elbow_flex.pos", "wrist_flex.pos", "wrist_roll.pos"]
            },
            "training_mode": "max_distance_forward",
            "direction_info": {
                "target_position": recorded_episode_info["target_position"],
                "direction_error_rad": recorded_episode_info["direction_error"],
                "direction_error_deg": np.degrees(recorded_episode_info["direction_error"]),
                "throw_velocity": recorded_episode_info["throw_velocity"],
                "direction_tolerance_rad": reward_cfg.get("direction_tolerance", 0.3),
                "direction_tolerance_deg": np.degrees(reward_cfg.get("direction_tolerance", 0.3)),
            },
            "control_frequency": env_cfg["control_freq"],
            "timestamp": time.strftime("%Y%m%d_%H%M%S")
        }
        
        # è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
        record_data = convert_to_json_serializable(record_data)
        
        record_json_path = os.path.join(log_dir, f"robot_control_sequence_{args.record_type}_ep{args.record_episode}.json")
        with open(record_json_path, 'w', encoding='utf-8') as f:
            json.dump(record_data, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆå¯æ‰§è¡Œçš„Pythonè„šæœ¬
        script_path = os.path.join(log_dir, f"robot_control_script_{args.record_type}_ep{args.record_episode}.py")
        generate_robot_control_script(recorded_joint_sequence, script_path, recorded_episode_info, args.record_type)
        
        record_type_desc = {
            "target": "ç›®æ ‡å…³èŠ‚è§’åº¦åºåˆ—(NNè¾“å‡º)",
            "state": "å®é™…å…³èŠ‚ä½ç½®çŠ¶æ€åºåˆ—"
        }[args.record_type]
        
        print(f"\nğŸ¬ {record_type_desc}è®°å½•å®Œæˆ!")
        print(f"ğŸ“„ JSONæ•°æ®ä¿å­˜è‡³: {record_json_path}")
        print(f"ğŸ Pythonè„šæœ¬ä¿å­˜è‡³: {script_path}")
        print(f"ğŸ“Š è®°å½•ç»Ÿè®¡:")
        print(f"  - Episode: {recorded_episode_info['episode']}")
        print(f"  - è®°å½•ç±»å‹: {args.record_type.upper()} ({record_type_desc})")
        print(f"  - æ€»æ­¥æ•°: {recorded_episode_info['total_steps']}")
        print(f"  - æ‰§è¡Œæ—¶é—´: {recorded_episode_info['total_steps'] * 0.02:.1f}ç§’")
        print(f"  - ç›®æ ‡ä½ç½®: {recorded_episode_info['target_position']}")
        print(f"  - å‰å‘åå·®: {np.degrees(recorded_episode_info['direction_error']):.1f}Â°")
        print(f"  - æŠ•æ·é€Ÿåº¦: {recorded_episode_info['throw_velocity']:.2f}m/s")
        print(f"  - æŠ•æ·è·ç¦»: {recorded_episode_info['throw_distance']:.3f}m")
        print(f"  - Episodeå¥–åŠ±: {recorded_episode_info['episode_reward']:.3f}")
        print(f"  - æ–¹å‘æˆåŠŸ: {'âœ…' if recorded_episode_info['direction_success'] else 'âŒ'}")
        print(f"  - è·ç¦»æˆåŠŸ: {'âœ…' if recorded_episode_info['distance_success'] else 'âŒ'}")
        print(f"  - ç»¼åˆæˆåŠŸ: {'âœ…' if recorded_episode_info['overall_success'] else 'âŒ'}")
        
        if args.record_type == "target":
            print(f"ğŸ’¡ ä½¿ç”¨æ–¹æ³• (è¿œè·ç¦»å‰å‘æŠ•æ·æ§åˆ¶):")
            print(f"  - ç›´æ¥è¿è¡Œè„šæœ¬: python {script_path}")
            print(f"  - æ•°æ®å¯ç›´æ¥ç”¨äºæœºå™¨äººè¿œè·ç¦»å‰å‘æŠ•æ·æ§åˆ¶")
        else:
            print(f"ğŸ’¡ ä½¿ç”¨æ–¹æ³• (æŠ•æ·è½¨è¿¹åˆ†æ):")
            print(f"  - åˆ†æè½¨è¿¹: python {script_path}")
            print(f"  - æ•°æ®ç”¨äºæŠ•æ·è½¨è¿¹åˆ†æï¼Œå¤ç°æ—¶éœ€è¦è½¬æ¢ä¸ºæ§åˆ¶å‘½ä»¤")
            
        print(f"  - æˆ–åŠ è½½JSONæ•°æ®è¿›è¡Œè‡ªå®šä¹‰å¤„ç†")
        print(f"ğŸ“ å…³èŠ‚è§’åº¦æ ¼å¼æ ·ä¾‹:")
        if recorded_joint_sequence:
            sample_angles = recorded_joint_sequence[0]
            print(f"  {{")
            for key, value in sample_angles.items():
                print(f"    '{key}': {value:.1f},")
            print(f"  }}")
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š è¿œè·ç¦»å‰å‘æŠ•æ·è¯„ä¼°ç»“æœæ±‡æ€»:")
    print("="*60)
    print(f"å¹³å‡Episodeå¥–åŠ±: {np.mean(episode_rewards):.2f} Â± {np.std(episode_rewards):.2f}")
    print(f"å¹³å‡å‰å‘åå·®: {np.degrees(np.mean(direction_errors)):.1f}Â° Â± {np.degrees(np.std(direction_errors)):.1f}Â°")
    print(f"å¹³å‡æŠ•æ·è·ç¦»: {np.mean(throw_distances):.3f} Â± {np.std(throw_distances):.3f}m")
    print(f"å¹³å‡æŠ•æ·é€Ÿåº¦: {np.mean(throw_velocities):.2f} Â± {np.std(throw_velocities):.2f}m/s")
    print(f"æœ€å°å‰å‘åå·®: {np.degrees(np.min(direction_errors)):.1f}Â°")
    print(f"æœ€å¤§å‰å‘åå·®: {np.degrees(np.max(direction_errors)):.1f}Â°")
    print(f"æœ€å¤§æŠ•æ·è·ç¦»: {np.max(throw_distances):.3f}m")
    
    # æˆåŠŸç‡ç»Ÿè®¡
    overall_success_rate = np.mean(success_rates) * 100
    direction_tolerance_deg = np.degrees(reward_cfg.get("direction_tolerance", 0.3))
    print(f"ç»¼åˆæˆåŠŸç‡: {overall_success_rate:.1f}% (å‰å‘åå·®<{direction_tolerance_deg:.1f}Â° + è·ç¦»â‰¥1.0m)")
    
    # å•é¡¹æˆåŠŸç‡
    direction_successes = [err <= reward_cfg.get("direction_tolerance", 0.3) for err in direction_errors]
    distance_successes = [dist >= 1.0 for dist in throw_distances]
    
    print(f"å‰å‘å‡†ç¡®ç‡: {np.mean(direction_successes) * 100:.1f}% (åå·®<{direction_tolerance_deg:.1f}Â°)")
    print(f"è·ç¦»æˆåŠŸç‡: {np.mean(distance_successes) * 100:.1f}% (è·ç¦»â‰¥1.0m)")
    
    # å‰å‘åå·®åˆ†å¸ƒç»Ÿè®¡
    print(f"\nå‰å‘åå·®åˆ†å¸ƒ:")
    print(f"  <5Â°:  {np.sum(np.array(direction_errors) < np.radians(5)) / len(direction_errors) * 100:.1f}%")
    print(f"  <10Â°: {np.sum(np.array(direction_errors) < np.radians(10)) / len(direction_errors) * 100:.1f}%")
    print(f"  <15Â°: {np.sum(np.array(direction_errors) < np.radians(15)) / len(direction_errors) * 100:.1f}%")
    print(f"  <20Â°: {np.sum(np.array(direction_errors) < np.radians(20)) / len(direction_errors) * 100:.1f}%")
    
    # å¯è§†åŒ–ç»“æœ
    if args.visualize:
        viz_path = os.path.join(log_dir, "distance_throw_results.png")
        base_pos = np.array([0.0, 0.0])  # æœºå™¨äººåŸºåº§ä½ç½®
        visualize_distance_throws(landing_positions, base_pos, viz_path)
        print(f"\nğŸ¨ è¿œè·ç¦»å‰å‘æŠ•æ·å¯è§†åŒ–ç»“æœä¿å­˜åœ¨: {viz_path}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results = {
        "episode_rewards": episode_rewards,
        "direction_errors": direction_errors,
        "throw_distances": throw_distances,
        "throw_velocities": throw_velocities,
        "landing_positions": landing_positions,
        "success_rates": success_rates,
        "throw_statistics": {
            "mean_direction_error_deg": float(np.degrees(np.mean(direction_errors))),
            "std_direction_error_deg": float(np.degrees(np.std(direction_errors))),
            "min_direction_error_deg": float(np.degrees(np.min(direction_errors))),
            "max_direction_error_deg": float(np.degrees(np.max(direction_errors))),
            "mean_throw_distance": float(np.mean(throw_distances)),
            "max_throw_distance": float(np.max(throw_distances)),
            "mean_throw_velocity": float(np.mean(throw_velocities)),
            "max_throw_velocity": float(np.max(throw_velocities)),
            "direction_success_rate": float(np.mean([err <= reward_cfg.get("direction_tolerance", 0.3) for err in direction_errors])),
            "distance_success_rate": float(np.mean([dist >= 1.0 for dist in throw_distances])),
            "overall_success_rate": float(np.mean(success_rates)),
        },
        "config": {
            "direction_tolerance_deg": float(np.degrees(reward_cfg.get("direction_tolerance", 0.3))),
            "target_position": command_cfg["target_position"],
            "training_mode": command_cfg["training_mode"],
            "num_episodes": args.num_episodes,
        }
    }
    
    # è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
    results = convert_to_json_serializable(results)
    
    results_path = os.path.join(log_dir, "evaluation_results.json")
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“„ è¯¦ç»†ç»“æœä¿å­˜åœ¨: {results_path}")
    print("="*60)

    # å¯è§†åŒ–å…³èŠ‚è§’åº¦è½¨è¿¹ï¼ˆå¦‚æœæœ‰Episode 0æ•°æ®ï¼‰
    if episode_0_joint_trajectory and episode_0_info:
        print(f"\nğŸ“ˆ ç”ŸæˆEpisode 0å…³èŠ‚è§’åº¦è½¨è¿¹å¯è§†åŒ–...")
        joint_trajectory_path = os.path.join(log_dir, "joint_trajectories_episode_0.png")
        # ä¼ é€’ä½ç½®ç›®æ ‡æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        position_targets = episode_0_info.get("position_targets", None)
        visualize_joint_trajectories(episode_0_joint_trajectory, env_cfg["control_freq"], joint_trajectory_path, episode_0_info, position_targets)
    else:
        print(f"\nâš ï¸  æœªæ‰¾åˆ°Episode 0çš„å…³èŠ‚è½¨è¿¹æ•°æ®ï¼Œè·³è¿‡å…³èŠ‚è§’åº¦è½¨è¿¹å¯è§†åŒ–")

if __name__ == "__main__":
    main()